---
layout: single
title:  "[python3]병렬처리2"
---

# 파이썬에서 병렬처리2

# 이전 병렬처리 포스트에서 확인된것을 보며 정리를 해보았다.

## 1. GIL이란? 왜 파이썬은 GIL을 사용할까?
파이썬은 메모리 관리를 위해 reference_count와 garbage collect를 사용한다.
reference_count는 생성되는 객체가 참조될 때 증가하고, 참조가 삭제될 때 감소한다.

```python
import sys

class class_reference_count_test():
  def __init__(self):
        pass

a = class_reference_count_test()
print("reference_count_test :", str(sys.getrefcount(a)))
b = a
print("reference_count_test :", str(sys.getrefcount(a)))
c = a
print("reference_count_test :", str(sys.getrefcount(a)))
c = 0
print("reference_count_test :", str(sys.getrefcount(a)))
b = 0
print("reference_count_test :", str(sys.getrefcount(a)))
```
    reference_count_test : 2
    reference_count_test : 3
    reference_count_test : 4
    reference_count_test : 3
    reference_count_test : 2

> 
<br/>

파이썬은 garbage collect에서 사용하지 않거나 reference_count 0인 객체 메모리를 회수한다.

즉, c언어에서는 프로그래머가 직접 malloc과 free를 했다면 파이썬은 Python Memory Manager가 관리를 해주기때문에 메모리를 직접 생성하고 해제하는 과정이 필요없다.

멀티스레드인 경우 여러 스레드가 하나의 객체를 사용한다면 refernce count를 관리하기 위해서 모든 객체에 대한 lock이 필요하다.

이러한 비효율을 막기 위해서 python에서 GIL을 사용하게 되었다.

하나의 Lock을 통해서 모든 객체들에 대한 refernce count의 동기화 문제를 해결한다.


## 2. 왜 싱글 스레드보다 멀티 스레드가 더 느릴까?
#### 싱글스레드 예제
```python
import random
import threading
import time


def working():
    max([random.random() for i in range(5000000)])


# 1 Thread
s_time = time.time()
working()
working()
working()
working()
working()
e_time = time.time()
print(f'{e_time - s_time:.5f}')

```
    결과 : 4.05095
---
<br/>

#### 멀티스레드 예제
```python
import random
import threading
import time


def working():
    max([random.random() for i in range(5000000)])


s_time = time.time()
threads = []
for i in range(5):
    threads.append(threading.Thread(target=working))
    threads[-1].start()

for t in threads:
    t.join()

e_time = time.time()
print(f'{e_time - s_time:.5f}')
```
    결과 : 4.32471

파이썬은 GIL 때문에 싱글스레드든 멀티스레드든 시간이득이 없다는것을 알지만, 왜 멀티스레드가 더 느릴까?

그 이유는 context switching에 따른 비용때문이다.

운영체제에서 하나의 CPU가 복수의 프로세스를 실행하기 위해선 프로세스 스케줄링이 필요하다. 프로세스 스케줄링이 없다면 CPU 하나당 하나의 프로세스만 돌아갈것이다.

거의 모든 OS(Windows, Linux, Mac)가 우선 순위 스케줄링과 라운드 로빈 스케줄링 알고리즘을 혼합한 선점형 스케줄링을 수행한다고 한다.

- 라운드-로빈 방식을 위한 Every Time Slice 
  - 동일 우선 순위의 다른 프로세스에게 CPU를 넘겨줘야 하는지 판단하기 위해 매 타임 슬라이스마다 스케쥴러가 동작해야 한다.

- 우선 순위 방식을 위한 프로세스 생성과 소멸
  - 우선 순위가 가장 높은 프로세서가 CPU를 차지해야 하므로, 현재 실행 중인 프로세스보다 더 높은 프로세스가 새로 생성되었는지, 더 높았던 프로세스가 종료되었는지를 알기 위해서는 프로세스가 생성되고 소멸될 때마다 스케쥴러가 동작해야 한다.

최근 OS들은 보통 15~20ms 간격으로 스케쥴링을 수행한다고 한다.

현재 실행중인 프로세스가 바뀌는 것은 Context switching이라고 하며, 수행 할 때마다 현재 CPU 내에 존재하는 레지스터 데이터는 메모리에 저장되고 

다음 프로세스 관련 메모리 데이터들로 CPU 레지스터는 채워된다.

즉, 멀티스레드의 예제 코드의 결과가 0.3초 차이나는 이유는 Context switching에 의한 비용 때문이다.


## 3. 이러한 차이에도 프로세스보다 스레드를 사용하는 이유?
메모리 문제로 통신 해야되는 경우 IPC를 사용해야하는데 이것도 비용이 들어가고 동기화 문제가 발생(뮤텍스, 세마포어)

blocking io(socket의 accept, sleep)등의 문제에선 스레드보다 프로세스의 이득이 없음

